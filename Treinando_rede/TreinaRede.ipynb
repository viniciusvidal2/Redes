{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TreinaRede.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"cBDMLJn6fiI-","colab_type":"text"},"cell_type":"markdown","source":["# **Acessa Google Drive e defini bibliotecas**"]},{"metadata":{"id":"o50FXaH9bkk9","colab_type":"code","outputId":"478bb84f-15da-42b1-9fb1-105b81d3a206","executionInfo":{"status":"ok","timestamp":1553002262349,"user_tz":180,"elapsed":1314,"user":{"displayName":"Guilherme Marins","photoUrl":"https://lh5.googleusercontent.com/-k8dz69umu6o/AAAAAAAAAAI/AAAAAAAAAAA/29U1bfi-L7A/s64/photo.jpg","userId":"02700118377328114409"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","%cd /content/drive/My Drive/Gui_e_Vini_e_Thataus_friends_4ever/Redes/Treinando_rede"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/My Drive/Gui_e_Vini_e_Thataus_friends_4ever/Redes/Treinando_rede\n"],"name":"stdout"}]},{"metadata":{"id":"FkUfIin8gaNK","colab_type":"text"},"cell_type":"markdown","source":["# **Programa Vini**"]},{"metadata":{"id":"mEhQGCTHTIlO","colab_type":"code","outputId":"c9afce9c-12e9-4d39-9da9-d0b2e5655f1a","colab":{"base_uri":"https://localhost:8080/","height":27863}},"cell_type":"code","source":["from keras.models import Sequential\n","from keras.models import load_model\n","\n","from keras.layers.core import Dense\n","from keras.layers import LSTM\n","\n","from keras.optimizers import SGD\n","from keras.optimizers import Adam\n","\n","from keras.callbacks import ModelCheckpoint\n","from keras.callbacks import EarlyStopping\n","\n","from keras.utils import plot_model\n","from keras.utils import np_utils\n","import matplotlib.pyplot as plt\n","\n","from rede_recursiva import Rede_recursiva\n","from rede_concatenada import Rede_concatenada\n","from rede_convolucional import Rede_convolucional\n","from rede_complexa import Rede_complexa\n","import ferramentas_leitura as fl\n","\n","import numpy as np\n","from numpy import array\n","\n","from sklearn.model_selection import train_test_split\n","\n","########################### Inicia lendo os dados, separando ou ja lendo de um arquivo\n","# As entradas vao ser inicialmente:\n","# > abertura\n","# > fechamento\n","# > minimo\n","# > maximo\n","# > media\n","# > volume\n","# As saidas vao ser inicialmente:\n","# > fechamento\n","# Deve definir quantos dias usar para treinar e descobrir o proximo\n","## CODIGO PARA A LEITURA DE DADOS UTILIZANDO O JOBLIB\n","#filePath = ['./../DATAYEAR/COTACAO_CMIG4_2011.txt', './../DATAYEAR/COTACAO_CMIG4_2012.txt', './../DATAYEAR/COTACAO_CMIG4_2013.txt', './../DATAYEAR/COTACAO_CMIG4_2014.txt',\n","#            './../DATAYEAR/COTACAO_CMIG4_2015.txt', './../DATAYEAR/COTACAO_CMIG4_2016.txt', './../DATAYEAR/COTACAO_CMIG4_2017.txt', './../DATAYEAR/COTACAO_CMIG4_2018.txt']\n","#filePath = ['./../DATAYEAR/COTACAO_ITUB4_2011.txt', './../DATAYEAR/COTACAO_ITUB4_2012.txt', './../DATAYEAR/COTACAO_ITUB4_2013.txt', './../DATAYEAR/COTACAO_ITUB4_2014.txt',\n","#            './../DATAYEAR/COTACAO_ITUB4_2015.txt', './../DATAYEAR/COTACAO_ITUB4_2016.txt', './../DATAYEAR/COTACAO_ITUB4_2017.txt', './../DATAYEAR/COTACAO_ITUB4_2018.txt']\n","filePath = ['./../DATAYEAR/COTACAO_PETR4_2015.txt', './../DATAYEAR/COTACAO_PETR4_2016.txt', './../DATAYEAR/COTACAO_PETR4_2017.txt', './../DATAYEAR/COTACAO_PETR4_2018.txt']\n","#filePath = ['./../DATAYEAR/COTACAO_BOVA11_2015.txt', './../DATAYEAR/COTACAO_BOVA11_2016.txt', './../DATAYEAR/COTACAO_BOVA11_2017.txt', './../DATAYEAR/COTACAO_BOVA11_2018.txt']\n","SampleSize = 15\n","Subsequences = 1\n","mascara_entradas = [1, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n","InputNumber = sum(mascara_entradas)\n","Dias_previstos = 5\n","OutputPositions = np.array([1]) # variaveis a serem previstas - olhar dentro da funcao\n","\n","# Organizando dados\n","print('Organizando dados...')\n","Data = fl.ReadData(filePath)\n","Data_norm, maximos, minimos, amplitudes = fl.Normalize(Data)\n","\n","X, Y = fl.OrganizeData(Data_norm, SampleSize, InputNumber, Dias_previstos, OutputPositions, mascara_entradas)\n","\n","X = X.reshape(X.shape[0], SampleSize, InputNumber)\n","Y = Y.reshape(Y.shape[0], Y.shape[1])\n","\n","# Uma vez feito o reshape e mais facil pegar o valor de fechamento e calcular \n","## Plotar aqui as saidas de fechamento e abertura em um grafico para analise visual de padroes\n","#plt.figure()\n","#plt.plot(np.arange(0, Y.shape[0]), Y[:, 0], label=\"Fechamento real\")\n","#plt.title('Dados Reais')\n","#plt.xlabel('Dia')\n","#plt.ylabel('Valor normalizado')\n","#plt.legend()\n","#plt.show(block=True)\n","\n","#### funciona aqui a separacao entre treino, validacao e teste automatica apos o reshape mesmo\n","#(trainx, val_testx, trainy, val_testy) = train_test_split(X        , Y        , test_size=0.3, random_state=20)\n","#(valx  , testx    , valy  , testy    ) = train_test_split(val_testx, val_testy, test_size=0.1, random_state=30)\n","\n","########################## Aqui separa os ultimos dias_teste dias para teste, porem o treino e validacao mantem sendo aleatorios no restante das amostras\n","intervalo_teste = np.arange(-10, -1) # epoca ainda desconhecida, amostras sequenciais\n","X_teste, Y_teste = X[intervalo_teste].copy(), Y[intervalo_teste].copy()\n","\n","dias_teste = np.arange(0, X_teste.shape[0], Dias_previstos) # testar sobre as amostras de teste em um intervalo de Dias_previstos\n","(testx, testy) = X_teste[dias_teste], Y_teste[dias_teste] # Dias que realmente havera teste sobre, entrarao na funcao predict\n","\n","Xtreino = np.delete(X, X.shape[0]+intervalo_teste, axis=0)\n","Ytreino = np.delete(Y, Y.shape[0]+intervalo_teste, axis=0)\n","#Xtreino = np.delete(X, intervalo_teste+X.shape[0], axis=0)\n","#Ytreino = np.delete(Y, intervalo_teste+X.shape[0], axis=0)\n","(trainx, valx, trainy, valy) = train_test_split(Xtreino, Ytreino, test_size=0.20, random_state=30)\n","\n","########################### Aqui monta a rede usando a classe desejada\n","treinar = True\n","if treinar:\n","    epocas = 2000 # por quantas epocas treinar\n","\n","    print(\"Criando otimizador e rede...\")\n","    adam = Adam(lr=0.0005, decay=0.000005, amsgrad=False)\n","    #rede = Rede_convolucional.montar(SampleSize, InputNumber, len(Out_posi))\n","    rede = Rede_recursiva.montar(SampleSize, InputNumber, Dias_previstos*len(OutputPositions))\n","    #rede = Rede_complexa.montar(SampleSize, InputNumber, 1)\n","    rede.compile(optimizer=adam, loss='mse')\n","    # Callbacks para salvar melhor rede e parar treino antes\n","    melhor_rede = ModelCheckpoint(\"Melhores_redes/atual.hdf5\", save_best_only=True, verbose=1, monitor='val_loss')\n","    parada_forcada = EarlyStopping(monitor='val_loss', patience=40, verbose=1)\n","    # Plotando arquitetura da rede\n","    plot_model(rede, \"Melhores_redes/arquitetura_atual.png\", show_shapes=True, show_layer_names=True)\n","\n","    # Aqui acontece o treino e ajuste de pesos realmente - observar BATCH SIZE\n","    print(\"Comecando o treinamento da rede...\")\n","    H = rede.fit(trainx, trainy, validation_data=(valx, valy), batch_size=50, epochs=epocas, callbacks=[melhor_rede], verbose=1)\n","\n","########################### Testar em cima da melhor rede possivel salva anteriormente\n","rede2 = load_model('Melhores_redes/atual.hdf5')\n","testx=valx\n","testy=valy\n","saida_teste = rede2.predict(testx, verbose=1)\n","\n","########################### Plot grafico da evolucao da rede\n","if treinar:\n","    plt.style.use(\"ggplot\")\n","    plt.plot(np.arange(0, len(H.history[\"loss\"])), H.history[\"loss\"], label=\"train_loss\")\n","    plt.plot(np.arange(0, len(H.history[\"val_loss\"])), H.history[\"val_loss\"], label=\"val_loss\")\n","    plt.title('Evolution')\n","    plt.xlabel('Epoch #')\n","    plt.ylabel('Value')\n","    plt.legend()\n","\n","# Preparando dados para plotar\n","conjunto_par   = np.arange(0, testy.shape[0], 2)\n","conjunto_impar = np.arange(1, testy.shape[0], 2)\n","\n","testey_par   = testy.copy()\n","testey_impar = testy.copy()\n","saida_teste_par   = saida_teste.copy()\n","saida_teste_impar = saida_teste.copy()\n","\n","#testey_par[conjunto_par]          = np.zeros([len(conjunto_par), 1])\n","#testey_impar[conjunto_impar]      = np.zeros([len(conjunto_impar), 1])\n","#saida_teste_par[conjunto_par]     = np.zeros([len(conjunto_par), 1])\n","#saida_teste_impar[conjunto_impar] = np.zeros([len(conjunto_impar), 1])\n","\n","#testy = testy[amostra_teste].flatten()\n","testey_par        = testey_par.flatten()\n","testey_impar      = testey_impar.flatten()\n","saida_teste_par   = saida_teste_par.flatten()\n","saida_teste_impar = saida_teste_impar.flatten()\n","\n","# Plot para comparacao com o conjunto de teste - Precos de saida de abertura e fechamento\n","plt.figure()\n","plt.plot(np.arange(0, testey_par.shape[0] )    , testey_par     , 'b+', label=\"Fechamento Real\")\n","plt.plot(np.arange(0, testey_impar.shape[0] )  , testey_impar   , 'k+', label=\"Fechamento Real\")\n","plt.plot(np.arange(0, saida_teste_par.shape[0])  , saida_teste_par  , 'ro', label=\"Fechamento Calculado\")\n","plt.plot(np.arange(0, saida_teste_impar.shape[0]), saida_teste_impar, 'mo', label=\"Fechamento Calculado\")\n","plt.title('Fechamento')\n","plt.xlabel('Dia')\n","plt.ylabel('Valor_norm')\n","plt.legend()\n","plt.grid()\n","\n","########################### Trazer de volta para valores reais\n","testy = testy.flatten()\n","saida_teste = saida_teste.flatten()\n","Y_real           = fl.ReturnRealValue(testy      , minimos, maximos, amplitudes, OutputPositions)\n","saida_teste_real = fl.ReturnRealValue(saida_teste, minimos, maximos, amplitudes, OutputPositions)\n","testey_par2        = fl.ReturnRealValue(testey_par, minimos, maximos, amplitudes, OutputPositions)\n","testey_impar2      = fl.ReturnRealValue(testey_impar, minimos, maximos, amplitudes, OutputPositions)\n","saida_teste_par2   = fl.ReturnRealValue(saida_teste_par, minimos, maximos, amplitudes, OutputPositions)\n","saida_teste_impar2 = fl.ReturnRealValue(saida_teste_impar, minimos, maximos, amplitudes, OutputPositions)\n","\n","plt.figure()\n","plt.plot(np.arange(0, Y_real.shape[0] )         , Y_real          , label=\"Fechamento Real\")\n","plt.plot(np.arange(0, saida_teste_real.shape[0]), saida_teste_real, label=\"Fechamento Calculado\")\n","plt.title('Fechamento')\n","plt.xlabel('Dia')\n","plt.ylabel('Valor R$')\n","plt.legend()\n","plt.grid()\n","\n","plt.figure()\n","plt.plot(np.arange(0, testey_par2.shape[0]), testey_par2, 'b+', label=\"Fechamento Real\")\n","plt.plot(np.arange(0, testey_impar2.shape[0]), testey_impar2, 'k+', label=\"Fechamento Real\")\n","plt.plot(np.arange(0, saida_teste_par2.shape[0]), saida_teste_par2, 'ro', label=\"Fechamento Calculado\")\n","plt.plot(np.arange(0, saida_teste_impar2.shape[0]), saida_teste_impar2, 'mo', label=\"Fechamento Calculado\")\n","plt.title('Fechamento')\n","plt.xlabel('Dia')\n","plt.ylabel('Valor R$')\n","plt.legend()\n","plt.grid()\n","\n"," #Calculo do erro entre os valores reais R$\n","erros = Y_real[0:len(saida_teste_real)] - saida_teste_real\n","media_erros = np.mean(erros)\n","media_erros_abs = np.mean(np.abs(erros))\n","erro_max = np.max(erros)\n","erro_min = np.min(erros)\n","\n","print('\\nA media dos erros e: {}\\t Sobre valores absolutos: {}'.format(media_erros, media_erros_abs))\n","print('\\nErro minimo R$     : {}\\t Erro maximo R$         : {}'.format(erro_min   , erro_max       ))\n","\n","plt.figure()\n","plt.plot(np.arange(0, erros.shape[0] ), erros, label=\"Erros\")\n","plt.title('Erros Real - Calculado')\n","plt.xlabel('Dia')\n","plt.ylabel('Valor R$')\n","plt.legend()\n","plt.grid()\n","\n","plt.show(block=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Organizando dados...\n","Criando otimizador e rede...\n","Comecando o treinamento da rede...\n","Train on 765 samples, validate on 192 samples\n","Epoch 1/2000\n","765/765 [==============================] - 3s 4ms/step - loss: 0.1808 - val_loss: 0.1579\n","\n","Epoch 00001: val_loss improved from inf to 0.15794, saving model to Melhores_redes/atual.hdf5\n","Epoch 2/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1744 - val_loss: 0.1499\n","\n","Epoch 00002: val_loss improved from 0.15794 to 0.14988, saving model to Melhores_redes/atual.hdf5\n","Epoch 3/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1671 - val_loss: 0.1442\n","\n","Epoch 00003: val_loss improved from 0.14988 to 0.14424, saving model to Melhores_redes/atual.hdf5\n","Epoch 4/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1626 - val_loss: 0.1401\n","\n","Epoch 00004: val_loss improved from 0.14424 to 0.14008, saving model to Melhores_redes/atual.hdf5\n","Epoch 5/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1591 - val_loss: 0.1372\n","\n","Epoch 00005: val_loss improved from 0.14008 to 0.13723, saving model to Melhores_redes/atual.hdf5\n","Epoch 6/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1560 - val_loss: 0.1354\n","\n","Epoch 00006: val_loss improved from 0.13723 to 0.13539, saving model to Melhores_redes/atual.hdf5\n","Epoch 7/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1552 - val_loss: 0.1342\n","\n","Epoch 00007: val_loss improved from 0.13539 to 0.13421, saving model to Melhores_redes/atual.hdf5\n","Epoch 8/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1524 - val_loss: 0.1335\n","\n","Epoch 00008: val_loss improved from 0.13421 to 0.13353, saving model to Melhores_redes/atual.hdf5\n","Epoch 9/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1514 - val_loss: 0.1331\n","\n","Epoch 00009: val_loss improved from 0.13353 to 0.13307, saving model to Melhores_redes/atual.hdf5\n","Epoch 10/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1509 - val_loss: 0.1328\n","\n","Epoch 00010: val_loss improved from 0.13307 to 0.13280, saving model to Melhores_redes/atual.hdf5\n","Epoch 11/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1503 - val_loss: 0.1326\n","\n","Epoch 00011: val_loss improved from 0.13280 to 0.13262, saving model to Melhores_redes/atual.hdf5\n","Epoch 12/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1494 - val_loss: 0.1325\n","\n","Epoch 00012: val_loss improved from 0.13262 to 0.13253, saving model to Melhores_redes/atual.hdf5\n","Epoch 13/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1495 - val_loss: 0.1324\n","\n","Epoch 00013: val_loss improved from 0.13253 to 0.13241, saving model to Melhores_redes/atual.hdf5\n","Epoch 14/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1488 - val_loss: 0.1323\n","\n","Epoch 00014: val_loss improved from 0.13241 to 0.13230, saving model to Melhores_redes/atual.hdf5\n","Epoch 15/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1492 - val_loss: 0.1319\n","\n","Epoch 00015: val_loss improved from 0.13230 to 0.13188, saving model to Melhores_redes/atual.hdf5\n","Epoch 16/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1484 - val_loss: 0.1315\n","\n","Epoch 00016: val_loss improved from 0.13188 to 0.13146, saving model to Melhores_redes/atual.hdf5\n","Epoch 17/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1478 - val_loss: 0.1310\n","\n","Epoch 00017: val_loss improved from 0.13146 to 0.13095, saving model to Melhores_redes/atual.hdf5\n","Epoch 18/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1476 - val_loss: 0.1305\n","\n","Epoch 00018: val_loss improved from 0.13095 to 0.13049, saving model to Melhores_redes/atual.hdf5\n","Epoch 19/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1471 - val_loss: 0.1299\n","\n","Epoch 00019: val_loss improved from 0.13049 to 0.12994, saving model to Melhores_redes/atual.hdf5\n","Epoch 20/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1466 - val_loss: 0.1292\n","\n","Epoch 00020: val_loss improved from 0.12994 to 0.12923, saving model to Melhores_redes/atual.hdf5\n","Epoch 21/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1454 - val_loss: 0.1284\n","\n","Epoch 00021: val_loss improved from 0.12923 to 0.12835, saving model to Melhores_redes/atual.hdf5\n","Epoch 22/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1455 - val_loss: 0.1274\n","\n","Epoch 00022: val_loss improved from 0.12835 to 0.12736, saving model to Melhores_redes/atual.hdf5\n","Epoch 23/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1440 - val_loss: 0.1265\n","\n","Epoch 00023: val_loss improved from 0.12736 to 0.12654, saving model to Melhores_redes/atual.hdf5\n","Epoch 24/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1423 - val_loss: 0.1253\n","\n","Epoch 00024: val_loss improved from 0.12654 to 0.12527, saving model to Melhores_redes/atual.hdf5\n","Epoch 25/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1394 - val_loss: 0.1232\n","\n","Epoch 00025: val_loss improved from 0.12527 to 0.12319, saving model to Melhores_redes/atual.hdf5\n","Epoch 26/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1371 - val_loss: 0.1187\n","\n","Epoch 00026: val_loss improved from 0.12319 to 0.11865, saving model to Melhores_redes/atual.hdf5\n","Epoch 27/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1321 - val_loss: 0.1116\n","\n","Epoch 00027: val_loss improved from 0.11865 to 0.11159, saving model to Melhores_redes/atual.hdf5\n","Epoch 28/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1264 - val_loss: 0.1031\n","\n","Epoch 00028: val_loss improved from 0.11159 to 0.10314, saving model to Melhores_redes/atual.hdf5\n","Epoch 29/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1171 - val_loss: 0.0898\n","\n","Epoch 00029: val_loss improved from 0.10314 to 0.08979, saving model to Melhores_redes/atual.hdf5\n","Epoch 30/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.1021 - val_loss: 0.0746\n","\n","Epoch 00030: val_loss improved from 0.08979 to 0.07457, saving model to Melhores_redes/atual.hdf5\n","Epoch 31/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0852 - val_loss: 0.0613\n","\n","Epoch 00031: val_loss improved from 0.07457 to 0.06134, saving model to Melhores_redes/atual.hdf5\n","Epoch 32/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0719 - val_loss: 0.0512\n","\n","Epoch 00032: val_loss improved from 0.06134 to 0.05120, saving model to Melhores_redes/atual.hdf5\n","Epoch 33/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0613 - val_loss: 0.0438\n","\n","Epoch 00033: val_loss improved from 0.05120 to 0.04377, saving model to Melhores_redes/atual.hdf5\n","Epoch 34/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0539 - val_loss: 0.0377\n","\n","Epoch 00034: val_loss improved from 0.04377 to 0.03768, saving model to Melhores_redes/atual.hdf5\n","Epoch 35/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0480 - val_loss: 0.0326\n","\n","Epoch 00035: val_loss improved from 0.03768 to 0.03255, saving model to Melhores_redes/atual.hdf5\n","Epoch 36/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0418 - val_loss: 0.0283\n","\n","Epoch 00036: val_loss improved from 0.03255 to 0.02827, saving model to Melhores_redes/atual.hdf5\n","Epoch 37/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0376 - val_loss: 0.0247\n","\n","Epoch 00037: val_loss improved from 0.02827 to 0.02474, saving model to Melhores_redes/atual.hdf5\n","Epoch 38/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0352 - val_loss: 0.0221\n","\n","Epoch 00038: val_loss improved from 0.02474 to 0.02206, saving model to Melhores_redes/atual.hdf5\n","Epoch 39/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0323 - val_loss: 0.0200\n","\n","Epoch 00039: val_loss improved from 0.02206 to 0.01997, saving model to Melhores_redes/atual.hdf5\n","Epoch 40/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0300 - val_loss: 0.0185\n","\n","Epoch 00040: val_loss improved from 0.01997 to 0.01846, saving model to Melhores_redes/atual.hdf5\n","Epoch 41/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0291 - val_loss: 0.0172\n","\n","Epoch 00041: val_loss improved from 0.01846 to 0.01724, saving model to Melhores_redes/atual.hdf5\n","Epoch 42/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0264 - val_loss: 0.0163\n","\n","Epoch 00042: val_loss improved from 0.01724 to 0.01628, saving model to Melhores_redes/atual.hdf5\n","Epoch 43/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0271 - val_loss: 0.0154\n","\n","Epoch 00043: val_loss improved from 0.01628 to 0.01538, saving model to Melhores_redes/atual.hdf5\n","Epoch 44/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0254 - val_loss: 0.0147\n","\n","Epoch 00044: val_loss improved from 0.01538 to 0.01467, saving model to Melhores_redes/atual.hdf5\n","Epoch 45/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0239 - val_loss: 0.0140\n","\n","Epoch 00045: val_loss improved from 0.01467 to 0.01396, saving model to Melhores_redes/atual.hdf5\n","Epoch 46/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0234 - val_loss: 0.0134\n","\n","Epoch 00046: val_loss improved from 0.01396 to 0.01338, saving model to Melhores_redes/atual.hdf5\n","Epoch 47/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0233 - val_loss: 0.0128\n","\n","Epoch 00047: val_loss improved from 0.01338 to 0.01278, saving model to Melhores_redes/atual.hdf5\n","Epoch 48/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0226 - val_loss: 0.0123\n","\n","Epoch 00048: val_loss improved from 0.01278 to 0.01227, saving model to Melhores_redes/atual.hdf5\n","Epoch 49/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0212 - val_loss: 0.0118\n","\n","Epoch 00049: val_loss improved from 0.01227 to 0.01177, saving model to Melhores_redes/atual.hdf5\n","Epoch 50/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0207 - val_loss: 0.0114\n","\n","Epoch 00050: val_loss improved from 0.01177 to 0.01141, saving model to Melhores_redes/atual.hdf5\n","Epoch 51/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0204 - val_loss: 0.0110\n","\n","Epoch 00051: val_loss improved from 0.01141 to 0.01097, saving model to Melhores_redes/atual.hdf5\n","Epoch 52/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0197 - val_loss: 0.0106\n","\n","Epoch 00052: val_loss improved from 0.01097 to 0.01060, saving model to Melhores_redes/atual.hdf5\n","Epoch 53/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0203 - val_loss: 0.0102\n","\n","Epoch 00053: val_loss improved from 0.01060 to 0.01022, saving model to Melhores_redes/atual.hdf5\n","Epoch 54/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0198 - val_loss: 0.0099\n","\n","Epoch 00054: val_loss improved from 0.01022 to 0.00990, saving model to Melhores_redes/atual.hdf5\n","Epoch 55/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0198 - val_loss: 0.0096\n","\n","Epoch 00055: val_loss improved from 0.00990 to 0.00963, saving model to Melhores_redes/atual.hdf5\n","Epoch 56/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0174 - val_loss: 0.0093\n","\n","Epoch 00056: val_loss improved from 0.00963 to 0.00933, saving model to Melhores_redes/atual.hdf5\n","Epoch 57/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.0090\n","\n","Epoch 00057: val_loss improved from 0.00933 to 0.00901, saving model to Melhores_redes/atual.hdf5\n","Epoch 58/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0164 - val_loss: 0.0087\n","\n","Epoch 00058: val_loss improved from 0.00901 to 0.00868, saving model to Melhores_redes/atual.hdf5\n","Epoch 59/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0172 - val_loss: 0.0084\n","\n","Epoch 00059: val_loss improved from 0.00868 to 0.00844, saving model to Melhores_redes/atual.hdf5\n","Epoch 60/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.0083\n","\n","Epoch 00060: val_loss improved from 0.00844 to 0.00826, saving model to Melhores_redes/atual.hdf5\n","Epoch 61/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0169 - val_loss: 0.0079\n","\n","Epoch 00061: val_loss improved from 0.00826 to 0.00794, saving model to Melhores_redes/atual.hdf5\n","Epoch 62/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0156 - val_loss: 0.0077\n","\n","Epoch 00062: val_loss improved from 0.00794 to 0.00773, saving model to Melhores_redes/atual.hdf5\n","Epoch 63/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0159 - val_loss: 0.0075\n","\n","Epoch 00063: val_loss improved from 0.00773 to 0.00745, saving model to Melhores_redes/atual.hdf5\n","Epoch 64/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0159 - val_loss: 0.0073\n","\n","Epoch 00064: val_loss improved from 0.00745 to 0.00729, saving model to Melhores_redes/atual.hdf5\n","Epoch 65/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0151 - val_loss: 0.0071\n","\n","Epoch 00065: val_loss improved from 0.00729 to 0.00712, saving model to Melhores_redes/atual.hdf5\n","Epoch 66/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0140 - val_loss: 0.0068\n","\n","Epoch 00066: val_loss improved from 0.00712 to 0.00684, saving model to Melhores_redes/atual.hdf5\n","Epoch 67/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0156 - val_loss: 0.0067\n","\n","Epoch 00067: val_loss improved from 0.00684 to 0.00669, saving model to Melhores_redes/atual.hdf5\n","Epoch 68/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0153 - val_loss: 0.0065\n","\n","Epoch 00068: val_loss improved from 0.00669 to 0.00652, saving model to Melhores_redes/atual.hdf5\n","Epoch 69/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0131 - val_loss: 0.0063\n","\n","Epoch 00069: val_loss improved from 0.00652 to 0.00628, saving model to Melhores_redes/atual.hdf5\n","Epoch 70/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0136 - val_loss: 0.0061\n","\n","Epoch 00070: val_loss improved from 0.00628 to 0.00606, saving model to Melhores_redes/atual.hdf5\n","Epoch 71/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0059\n","\n","Epoch 00071: val_loss improved from 0.00606 to 0.00586, saving model to Melhores_redes/atual.hdf5\n","Epoch 72/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0132 - val_loss: 0.0057\n","\n","Epoch 00072: val_loss improved from 0.00586 to 0.00571, saving model to Melhores_redes/atual.hdf5\n","Epoch 73/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.0055\n","\n","Epoch 00073: val_loss improved from 0.00571 to 0.00552, saving model to Melhores_redes/atual.hdf5\n","Epoch 74/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0132 - val_loss: 0.0055\n","\n","Epoch 00074: val_loss improved from 0.00552 to 0.00546, saving model to Melhores_redes/atual.hdf5\n","Epoch 75/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0134 - val_loss: 0.0053\n","\n","Epoch 00075: val_loss improved from 0.00546 to 0.00530, saving model to Melhores_redes/atual.hdf5\n","Epoch 76/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0132 - val_loss: 0.0051\n","\n","Epoch 00076: val_loss improved from 0.00530 to 0.00512, saving model to Melhores_redes/atual.hdf5\n","Epoch 77/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0133 - val_loss: 0.0050\n","\n","Epoch 00077: val_loss improved from 0.00512 to 0.00502, saving model to Melhores_redes/atual.hdf5\n","Epoch 78/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0126 - val_loss: 0.0049\n","\n","Epoch 00078: val_loss improved from 0.00502 to 0.00487, saving model to Melhores_redes/atual.hdf5\n","Epoch 79/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0048\n","\n","Epoch 00079: val_loss improved from 0.00487 to 0.00476, saving model to Melhores_redes/atual.hdf5\n","Epoch 80/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0129 - val_loss: 0.0046\n","\n","Epoch 00080: val_loss improved from 0.00476 to 0.00461, saving model to Melhores_redes/atual.hdf5\n","Epoch 81/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0045\n","\n","Epoch 00081: val_loss improved from 0.00461 to 0.00450, saving model to Melhores_redes/atual.hdf5\n","Epoch 82/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0044\n","\n","Epoch 00082: val_loss improved from 0.00450 to 0.00439, saving model to Melhores_redes/atual.hdf5\n","Epoch 83/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0043\n","\n","Epoch 00083: val_loss improved from 0.00439 to 0.00431, saving model to Melhores_redes/atual.hdf5\n","Epoch 84/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0042\n","\n","Epoch 00084: val_loss improved from 0.00431 to 0.00416, saving model to Melhores_redes/atual.hdf5\n","Epoch 85/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0110 - val_loss: 0.0040\n","\n","Epoch 00085: val_loss improved from 0.00416 to 0.00398, saving model to Melhores_redes/atual.hdf5\n","Epoch 86/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0040\n","\n","Epoch 00086: val_loss improved from 0.00398 to 0.00396, saving model to Melhores_redes/atual.hdf5\n","Epoch 87/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0112 - val_loss: 0.0039\n","\n","Epoch 00087: val_loss improved from 0.00396 to 0.00390, saving model to Melhores_redes/atual.hdf5\n","Epoch 88/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0039\n","\n","Epoch 00088: val_loss improved from 0.00390 to 0.00388, saving model to Melhores_redes/atual.hdf5\n","Epoch 89/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0038\n","\n","Epoch 00089: val_loss improved from 0.00388 to 0.00382, saving model to Melhores_redes/atual.hdf5\n","Epoch 90/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0112 - val_loss: 0.0037\n","\n","Epoch 00090: val_loss improved from 0.00382 to 0.00372, saving model to Melhores_redes/atual.hdf5\n","Epoch 91/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0036\n","\n","Epoch 00091: val_loss improved from 0.00372 to 0.00363, saving model to Melhores_redes/atual.hdf5\n","Epoch 92/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0036\n","\n","Epoch 00092: val_loss improved from 0.00363 to 0.00355, saving model to Melhores_redes/atual.hdf5\n","Epoch 93/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0115 - val_loss: 0.0035\n","\n","Epoch 00093: val_loss improved from 0.00355 to 0.00346, saving model to Melhores_redes/atual.hdf5\n","Epoch 94/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0034\n","\n","Epoch 00094: val_loss improved from 0.00346 to 0.00344, saving model to Melhores_redes/atual.hdf5\n","Epoch 95/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0099 - val_loss: 0.0034\n","\n","Epoch 00095: val_loss improved from 0.00344 to 0.00336, saving model to Melhores_redes/atual.hdf5\n","Epoch 96/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0101 - val_loss: 0.0033\n","\n","Epoch 00096: val_loss improved from 0.00336 to 0.00331, saving model to Melhores_redes/atual.hdf5\n","Epoch 97/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0033\n","\n","Epoch 00097: val_loss improved from 0.00331 to 0.00327, saving model to Melhores_redes/atual.hdf5\n","Epoch 98/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0032\n","\n","Epoch 00098: val_loss improved from 0.00327 to 0.00325, saving model to Melhores_redes/atual.hdf5\n","Epoch 99/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0032\n","\n","Epoch 00099: val_loss improved from 0.00325 to 0.00322, saving model to Melhores_redes/atual.hdf5\n","Epoch 100/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0031\n","\n","Epoch 00100: val_loss improved from 0.00322 to 0.00314, saving model to Melhores_redes/atual.hdf5\n","Epoch 101/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0100 - val_loss: 0.0031\n","\n","Epoch 00101: val_loss improved from 0.00314 to 0.00307, saving model to Melhores_redes/atual.hdf5\n","Epoch 102/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0030\n","\n","Epoch 00102: val_loss improved from 0.00307 to 0.00296, saving model to Melhores_redes/atual.hdf5\n","Epoch 103/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0029\n","\n","Epoch 00103: val_loss improved from 0.00296 to 0.00292, saving model to Melhores_redes/atual.hdf5\n","Epoch 104/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0030\n","\n","Epoch 00104: val_loss did not improve from 0.00292\n","Epoch 105/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0029\n","\n","Epoch 00105: val_loss did not improve from 0.00292\n","Epoch 106/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0029\n","\n","Epoch 00106: val_loss improved from 0.00292 to 0.00290, saving model to Melhores_redes/atual.hdf5\n","Epoch 107/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0029\n","\n","Epoch 00107: val_loss improved from 0.00290 to 0.00287, saving model to Melhores_redes/atual.hdf5\n","Epoch 108/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0029\n","\n","Epoch 00108: val_loss did not improve from 0.00287\n","Epoch 109/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0029\n","\n","Epoch 00109: val_loss did not improve from 0.00287\n","Epoch 110/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0028\n","\n","Epoch 00110: val_loss improved from 0.00287 to 0.00277, saving model to Melhores_redes/atual.hdf5\n","Epoch 111/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0027\n","\n","Epoch 00111: val_loss improved from 0.00277 to 0.00266, saving model to Melhores_redes/atual.hdf5\n","Epoch 112/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0027\n","\n","Epoch 00112: val_loss improved from 0.00266 to 0.00266, saving model to Melhores_redes/atual.hdf5\n","Epoch 113/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0026\n","\n","Epoch 00113: val_loss improved from 0.00266 to 0.00264, saving model to Melhores_redes/atual.hdf5\n","Epoch 114/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0074 - val_loss: 0.0026\n","\n","Epoch 00114: val_loss improved from 0.00264 to 0.00264, saving model to Melhores_redes/atual.hdf5\n","Epoch 115/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0025\n","\n","Epoch 00115: val_loss improved from 0.00264 to 0.00254, saving model to Melhores_redes/atual.hdf5\n","Epoch 116/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0025\n","\n","Epoch 00116: val_loss improved from 0.00254 to 0.00252, saving model to Melhores_redes/atual.hdf5\n","Epoch 117/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0025\n","\n","Epoch 00117: val_loss improved from 0.00252 to 0.00250, saving model to Melhores_redes/atual.hdf5\n","Epoch 118/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0025\n","\n","Epoch 00118: val_loss improved from 0.00250 to 0.00250, saving model to Melhores_redes/atual.hdf5\n","Epoch 119/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0025\n","\n","Epoch 00119: val_loss improved from 0.00250 to 0.00248, saving model to Melhores_redes/atual.hdf5\n","Epoch 120/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0025\n","\n","Epoch 00120: val_loss improved from 0.00248 to 0.00247, saving model to Melhores_redes/atual.hdf5\n","Epoch 121/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0025\n","\n","Epoch 00121: val_loss did not improve from 0.00247\n","Epoch 122/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0024\n","\n","Epoch 00122: val_loss improved from 0.00247 to 0.00238, saving model to Melhores_redes/atual.hdf5\n","Epoch 123/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0023\n","\n","Epoch 00123: val_loss improved from 0.00238 to 0.00233, saving model to Melhores_redes/atual.hdf5\n","Epoch 124/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0023\n","\n","Epoch 00124: val_loss improved from 0.00233 to 0.00232, saving model to Melhores_redes/atual.hdf5\n","Epoch 125/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0023\n","\n","Epoch 00125: val_loss improved from 0.00232 to 0.00228, saving model to Melhores_redes/atual.hdf5\n","Epoch 126/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0023\n","\n","Epoch 00126: val_loss improved from 0.00228 to 0.00227, saving model to Melhores_redes/atual.hdf5\n","Epoch 127/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0022\n","\n","Epoch 00127: val_loss improved from 0.00227 to 0.00223, saving model to Melhores_redes/atual.hdf5\n","Epoch 128/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0023\n","\n","Epoch 00128: val_loss did not improve from 0.00223\n","Epoch 129/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0074 - val_loss: 0.0022\n","\n","Epoch 00129: val_loss did not improve from 0.00223\n","Epoch 130/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0022\n","\n","Epoch 00130: val_loss improved from 0.00223 to 0.00221, saving model to Melhores_redes/atual.hdf5\n","Epoch 131/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0022\n","\n","Epoch 00131: val_loss did not improve from 0.00221\n","Epoch 132/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0022\n","\n","Epoch 00132: val_loss improved from 0.00221 to 0.00220, saving model to Melhores_redes/atual.hdf5\n","Epoch 133/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0066 - val_loss: 0.0022\n","\n","Epoch 00133: val_loss did not improve from 0.00220\n","Epoch 134/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0070 - val_loss: 0.0022\n","\n","Epoch 00134: val_loss improved from 0.00220 to 0.00217, saving model to Melhores_redes/atual.hdf5\n","Epoch 135/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0021\n","\n","Epoch 00135: val_loss improved from 0.00217 to 0.00215, saving model to Melhores_redes/atual.hdf5\n","Epoch 136/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0074 - val_loss: 0.0021\n","\n","Epoch 00136: val_loss improved from 0.00215 to 0.00211, saving model to Melhores_redes/atual.hdf5\n","Epoch 137/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0070 - val_loss: 0.0022\n","\n","Epoch 00137: val_loss did not improve from 0.00211\n","Epoch 138/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0021\n","\n","Epoch 00138: val_loss improved from 0.00211 to 0.00209, saving model to Melhores_redes/atual.hdf5\n","Epoch 139/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0021\n","\n","Epoch 00139: val_loss did not improve from 0.00209\n","Epoch 140/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0021\n","\n","Epoch 00140: val_loss did not improve from 0.00209\n","Epoch 141/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0074 - val_loss: 0.0021\n","\n","Epoch 00141: val_loss improved from 0.00209 to 0.00206, saving model to Melhores_redes/atual.hdf5\n","Epoch 142/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0073 - val_loss: 0.0021\n","\n","Epoch 00142: val_loss did not improve from 0.00206\n","Epoch 143/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0067 - val_loss: 0.0021\n","\n","Epoch 00143: val_loss improved from 0.00206 to 0.00205, saving model to Melhores_redes/atual.hdf5\n","Epoch 144/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0074 - val_loss: 0.0020\n","\n","Epoch 00144: val_loss improved from 0.00205 to 0.00204, saving model to Melhores_redes/atual.hdf5\n","Epoch 145/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0021\n","\n","Epoch 00145: val_loss did not improve from 0.00204\n","Epoch 146/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0061 - val_loss: 0.0020\n","\n","Epoch 00146: val_loss improved from 0.00204 to 0.00202, saving model to Melhores_redes/atual.hdf5\n","Epoch 147/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0071 - val_loss: 0.0020\n","\n","Epoch 00147: val_loss did not improve from 0.00202\n","Epoch 148/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0020\n","\n","Epoch 00148: val_loss did not improve from 0.00202\n","Epoch 149/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0067 - val_loss: 0.0020\n","\n","Epoch 00149: val_loss improved from 0.00202 to 0.00199, saving model to Melhores_redes/atual.hdf5\n","Epoch 150/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0062 - val_loss: 0.0020\n","\n","Epoch 00150: val_loss did not improve from 0.00199\n","Epoch 151/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0070 - val_loss: 0.0020\n","\n","Epoch 00151: val_loss improved from 0.00199 to 0.00196, saving model to Melhores_redes/atual.hdf5\n","Epoch 152/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0067 - val_loss: 0.0019\n","\n","Epoch 00152: val_loss improved from 0.00196 to 0.00191, saving model to Melhores_redes/atual.hdf5\n","Epoch 153/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0019\n","\n","Epoch 00153: val_loss did not improve from 0.00191\n","Epoch 154/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0064 - val_loss: 0.0019\n","\n","Epoch 00154: val_loss improved from 0.00191 to 0.00191, saving model to Melhores_redes/atual.hdf5\n","Epoch 155/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0068 - val_loss: 0.0019\n","\n","Epoch 00155: val_loss improved from 0.00191 to 0.00189, saving model to Melhores_redes/atual.hdf5\n","Epoch 156/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0065 - val_loss: 0.0019\n","\n","Epoch 00156: val_loss improved from 0.00189 to 0.00188, saving model to Melhores_redes/atual.hdf5\n","Epoch 157/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0065 - val_loss: 0.0019\n","\n","Epoch 00157: val_loss did not improve from 0.00188\n","Epoch 158/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0067 - val_loss: 0.0019\n","\n","Epoch 00158: val_loss did not improve from 0.00188\n","Epoch 159/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0057 - val_loss: 0.0019\n","\n","Epoch 00159: val_loss did not improve from 0.00188\n","Epoch 160/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0063 - val_loss: 0.0019\n","\n","Epoch 00160: val_loss improved from 0.00188 to 0.00186, saving model to Melhores_redes/atual.hdf5\n","Epoch 161/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0064 - val_loss: 0.0018\n","\n","Epoch 00161: val_loss improved from 0.00186 to 0.00184, saving model to Melhores_redes/atual.hdf5\n","Epoch 162/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0060 - val_loss: 0.0018\n","\n","Epoch 00162: val_loss did not improve from 0.00184\n","Epoch 163/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0059 - val_loss: 0.0019\n","\n","Epoch 00163: val_loss did not improve from 0.00184\n","Epoch 164/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0063 - val_loss: 0.0018\n","\n","Epoch 00164: val_loss improved from 0.00184 to 0.00181, saving model to Melhores_redes/atual.hdf5\n","Epoch 165/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0064 - val_loss: 0.0018\n","\n","Epoch 00165: val_loss improved from 0.00181 to 0.00178, saving model to Melhores_redes/atual.hdf5\n","Epoch 166/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0019\n","\n","Epoch 00166: val_loss did not improve from 0.00178\n","Epoch 167/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0063 - val_loss: 0.0018\n","\n","Epoch 00167: val_loss improved from 0.00178 to 0.00178, saving model to Melhores_redes/atual.hdf5\n","Epoch 168/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0064 - val_loss: 0.0018\n","\n","Epoch 00168: val_loss improved from 0.00178 to 0.00176, saving model to Melhores_redes/atual.hdf5\n","Epoch 169/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0061 - val_loss: 0.0017\n","\n","Epoch 00169: val_loss improved from 0.00176 to 0.00175, saving model to Melhores_redes/atual.hdf5\n","Epoch 170/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0018\n","\n","Epoch 00170: val_loss did not improve from 0.00175\n","Epoch 171/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0070 - val_loss: 0.0018\n","\n","Epoch 00171: val_loss did not improve from 0.00175\n","Epoch 172/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0061 - val_loss: 0.0018\n","\n","Epoch 00172: val_loss did not improve from 0.00175\n","Epoch 173/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0018\n","\n","Epoch 00173: val_loss did not improve from 0.00175\n","Epoch 174/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0054 - val_loss: 0.0018\n","\n","Epoch 00174: val_loss did not improve from 0.00175\n","Epoch 175/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0054 - val_loss: 0.0018\n","\n","Epoch 00175: val_loss did not improve from 0.00175\n","Epoch 176/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0059 - val_loss: 0.0017\n","\n","Epoch 00176: val_loss improved from 0.00175 to 0.00174, saving model to Melhores_redes/atual.hdf5\n","Epoch 177/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0062 - val_loss: 0.0017\n","\n","Epoch 00177: val_loss improved from 0.00174 to 0.00170, saving model to Melhores_redes/atual.hdf5\n","Epoch 178/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0060 - val_loss: 0.0017\n","\n","Epoch 00178: val_loss improved from 0.00170 to 0.00168, saving model to Melhores_redes/atual.hdf5\n","Epoch 179/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0017\n","\n","Epoch 00179: val_loss did not improve from 0.00168\n","Epoch 180/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0060 - val_loss: 0.0017\n","\n","Epoch 00180: val_loss did not improve from 0.00168\n","Epoch 181/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0063 - val_loss: 0.0017\n","\n","Epoch 00181: val_loss did not improve from 0.00168\n","Epoch 182/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0017\n","\n","Epoch 00182: val_loss improved from 0.00168 to 0.00168, saving model to Melhores_redes/atual.hdf5\n","Epoch 183/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0054 - val_loss: 0.0017\n","\n","Epoch 00183: val_loss did not improve from 0.00168\n","Epoch 184/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0017\n","\n","Epoch 00184: val_loss did not improve from 0.00168\n","Epoch 185/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0054 - val_loss: 0.0017\n","\n","Epoch 00185: val_loss improved from 0.00168 to 0.00167, saving model to Melhores_redes/atual.hdf5\n","Epoch 186/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0055 - val_loss: 0.0017\n","\n","Epoch 00186: val_loss improved from 0.00167 to 0.00166, saving model to Melhores_redes/atual.hdf5\n","Epoch 187/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0054 - val_loss: 0.0016\n","\n","Epoch 00187: val_loss improved from 0.00166 to 0.00165, saving model to Melhores_redes/atual.hdf5\n","Epoch 188/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0053 - val_loss: 0.0016\n","\n","Epoch 00188: val_loss improved from 0.00165 to 0.00163, saving model to Melhores_redes/atual.hdf5\n","Epoch 189/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0048 - val_loss: 0.0016\n","\n","Epoch 00189: val_loss improved from 0.00163 to 0.00162, saving model to Melhores_redes/atual.hdf5\n","Epoch 190/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0050 - val_loss: 0.0016\n","\n","Epoch 00190: val_loss did not improve from 0.00162\n","Epoch 191/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0016\n","\n","Epoch 00191: val_loss improved from 0.00162 to 0.00160, saving model to Melhores_redes/atual.hdf5\n","Epoch 192/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0053 - val_loss: 0.0016\n","\n","Epoch 00192: val_loss improved from 0.00160 to 0.00159, saving model to Melhores_redes/atual.hdf5\n","Epoch 193/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0053 - val_loss: 0.0016\n","\n","Epoch 00193: val_loss did not improve from 0.00159\n","Epoch 194/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0016\n","\n","Epoch 00194: val_loss improved from 0.00159 to 0.00157, saving model to Melhores_redes/atual.hdf5\n","Epoch 195/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0017\n","\n","Epoch 00195: val_loss did not improve from 0.00157\n","Epoch 196/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0016\n","\n","Epoch 00196: val_loss did not improve from 0.00157\n","Epoch 197/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0049 - val_loss: 0.0016\n","\n","Epoch 00197: val_loss did not improve from 0.00157\n","Epoch 198/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0060 - val_loss: 0.0016\n","\n","Epoch 00198: val_loss improved from 0.00157 to 0.00156, saving model to Melhores_redes/atual.hdf5\n","Epoch 199/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0055 - val_loss: 0.0015\n","\n","Epoch 00199: val_loss improved from 0.00156 to 0.00155, saving model to Melhores_redes/atual.hdf5\n","Epoch 200/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0055 - val_loss: 0.0016\n","\n","Epoch 00200: val_loss did not improve from 0.00155\n","Epoch 201/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0054 - val_loss: 0.0016\n","\n","Epoch 00201: val_loss did not improve from 0.00155\n","Epoch 202/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0050 - val_loss: 0.0016\n","\n","Epoch 00202: val_loss did not improve from 0.00155\n","Epoch 203/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0015\n","\n","Epoch 00203: val_loss improved from 0.00155 to 0.00155, saving model to Melhores_redes/atual.hdf5\n","Epoch 204/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0057 - val_loss: 0.0015\n","\n","Epoch 00204: val_loss did not improve from 0.00155\n","Epoch 205/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0055 - val_loss: 0.0016\n","\n","Epoch 00205: val_loss did not improve from 0.00155\n","Epoch 206/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0015\n","\n","Epoch 00206: val_loss did not improve from 0.00155\n","Epoch 207/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0016\n","\n","Epoch 00207: val_loss did not improve from 0.00155\n","Epoch 208/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0015\n","\n","Epoch 00208: val_loss improved from 0.00155 to 0.00154, saving model to Melhores_redes/atual.hdf5\n","Epoch 209/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0050 - val_loss: 0.0016\n","\n","Epoch 00209: val_loss did not improve from 0.00154\n","Epoch 210/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0055 - val_loss: 0.0015\n","\n","Epoch 00210: val_loss did not improve from 0.00154\n","Epoch 211/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0055 - val_loss: 0.0015\n","\n","Epoch 00211: val_loss improved from 0.00154 to 0.00152, saving model to Melhores_redes/atual.hdf5\n","Epoch 212/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0015\n","\n","Epoch 00212: val_loss did not improve from 0.00152\n","Epoch 213/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0015\n","\n","Epoch 00213: val_loss improved from 0.00152 to 0.00151, saving model to Melhores_redes/atual.hdf5\n","Epoch 214/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0015\n","\n","Epoch 00214: val_loss did not improve from 0.00151\n","Epoch 215/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0048 - val_loss: 0.0015\n","\n","Epoch 00215: val_loss improved from 0.00151 to 0.00150, saving model to Melhores_redes/atual.hdf5\n","Epoch 216/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0015\n","\n","Epoch 00216: val_loss improved from 0.00150 to 0.00148, saving model to Melhores_redes/atual.hdf5\n","Epoch 217/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0015\n","\n","Epoch 00217: val_loss improved from 0.00148 to 0.00148, saving model to Melhores_redes/atual.hdf5\n","Epoch 218/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0015\n","\n","Epoch 00218: val_loss improved from 0.00148 to 0.00148, saving model to Melhores_redes/atual.hdf5\n","Epoch 219/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0048 - val_loss: 0.0015\n","\n","Epoch 00219: val_loss improved from 0.00148 to 0.00148, saving model to Melhores_redes/atual.hdf5\n","Epoch 220/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0049 - val_loss: 0.0015\n","\n","Epoch 00220: val_loss did not improve from 0.00148\n","Epoch 221/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0015\n","\n","Epoch 00221: val_loss improved from 0.00148 to 0.00147, saving model to Melhores_redes/atual.hdf5\n","Epoch 222/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0015\n","\n","Epoch 00222: val_loss improved from 0.00147 to 0.00147, saving model to Melhores_redes/atual.hdf5\n","Epoch 223/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0049 - val_loss: 0.0015\n","\n","Epoch 00223: val_loss improved from 0.00147 to 0.00147, saving model to Melhores_redes/atual.hdf5\n","Epoch 224/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0056 - val_loss: 0.0015\n","\n","Epoch 00224: val_loss did not improve from 0.00147\n","Epoch 225/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0015\n","\n","Epoch 00225: val_loss improved from 0.00147 to 0.00147, saving model to Melhores_redes/atual.hdf5\n","Epoch 226/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0049 - val_loss: 0.0015\n","\n","Epoch 00226: val_loss did not improve from 0.00147\n","Epoch 227/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0015\n","\n","Epoch 00227: val_loss improved from 0.00147 to 0.00146, saving model to Melhores_redes/atual.hdf5\n","Epoch 228/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0014\n","\n","Epoch 00228: val_loss improved from 0.00146 to 0.00145, saving model to Melhores_redes/atual.hdf5\n","Epoch 229/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0015\n","\n","Epoch 00229: val_loss did not improve from 0.00145\n","Epoch 230/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0015\n","\n","Epoch 00230: val_loss did not improve from 0.00145\n","Epoch 231/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0014\n","\n","Epoch 00231: val_loss improved from 0.00145 to 0.00142, saving model to Melhores_redes/atual.hdf5\n","Epoch 232/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0048 - val_loss: 0.0014\n","\n","Epoch 00232: val_loss improved from 0.00142 to 0.00142, saving model to Melhores_redes/atual.hdf5\n","Epoch 233/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0050 - val_loss: 0.0014\n","\n","Epoch 00233: val_loss improved from 0.00142 to 0.00141, saving model to Melhores_redes/atual.hdf5\n","Epoch 234/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0050 - val_loss: 0.0014\n","\n","Epoch 00234: val_loss improved from 0.00141 to 0.00140, saving model to Melhores_redes/atual.hdf5\n","Epoch 235/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0014\n","\n","Epoch 00235: val_loss did not improve from 0.00140\n","Epoch 236/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0014\n","\n","Epoch 00236: val_loss did not improve from 0.00140\n","Epoch 237/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0014\n","\n","Epoch 00237: val_loss improved from 0.00140 to 0.00140, saving model to Melhores_redes/atual.hdf5\n","Epoch 238/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0014\n","\n","Epoch 00238: val_loss did not improve from 0.00140\n","Epoch 239/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0048 - val_loss: 0.0014\n","\n","Epoch 00239: val_loss improved from 0.00140 to 0.00138, saving model to Melhores_redes/atual.hdf5\n","Epoch 240/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0014\n","\n","Epoch 00240: val_loss did not improve from 0.00138\n","Epoch 241/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0014\n","\n","Epoch 00241: val_loss did not improve from 0.00138\n","Epoch 242/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0048 - val_loss: 0.0014\n","\n","Epoch 00242: val_loss did not improve from 0.00138\n","Epoch 243/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0014\n","\n","Epoch 00243: val_loss improved from 0.00138 to 0.00138, saving model to Melhores_redes/atual.hdf5\n","Epoch 244/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0014\n","\n","Epoch 00244: val_loss did not improve from 0.00138\n","Epoch 245/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0014\n","\n","Epoch 00245: val_loss did not improve from 0.00138\n","Epoch 246/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0014\n","\n","Epoch 00246: val_loss did not improve from 0.00138\n","Epoch 247/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0014\n","\n","Epoch 00247: val_loss did not improve from 0.00138\n","Epoch 248/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0014\n","\n","Epoch 00248: val_loss improved from 0.00138 to 0.00136, saving model to Melhores_redes/atual.hdf5\n","Epoch 249/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0014\n","\n","Epoch 00249: val_loss did not improve from 0.00136\n","Epoch 250/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0014\n","\n","Epoch 00250: val_loss did not improve from 0.00136\n","Epoch 251/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0014\n","\n","Epoch 00251: val_loss did not improve from 0.00136\n","Epoch 252/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0049 - val_loss: 0.0014\n","\n","Epoch 00252: val_loss did not improve from 0.00136\n","Epoch 253/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0014\n","\n","Epoch 00253: val_loss did not improve from 0.00136\n","Epoch 254/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0013\n","\n","Epoch 00254: val_loss improved from 0.00136 to 0.00134, saving model to Melhores_redes/atual.hdf5\n","Epoch 255/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0014\n","\n","Epoch 00255: val_loss did not improve from 0.00134\n","Epoch 256/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0014\n","\n","Epoch 00256: val_loss did not improve from 0.00134\n","Epoch 257/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0014\n","\n","Epoch 00257: val_loss did not improve from 0.00134\n","Epoch 258/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0014\n","\n","Epoch 00258: val_loss did not improve from 0.00134\n","Epoch 259/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0014\n","\n","Epoch 00259: val_loss did not improve from 0.00134\n","Epoch 260/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0013\n","\n","Epoch 00260: val_loss improved from 0.00134 to 0.00133, saving model to Melhores_redes/atual.hdf5\n","Epoch 261/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0013\n","\n","Epoch 00261: val_loss improved from 0.00133 to 0.00133, saving model to Melhores_redes/atual.hdf5\n","Epoch 262/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0013\n","\n","Epoch 00262: val_loss did not improve from 0.00133\n","Epoch 263/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0013\n","\n","Epoch 00263: val_loss improved from 0.00133 to 0.00133, saving model to Melhores_redes/atual.hdf5\n","Epoch 264/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0013\n","\n","Epoch 00264: val_loss improved from 0.00133 to 0.00132, saving model to Melhores_redes/atual.hdf5\n","Epoch 265/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0047 - val_loss: 0.0013\n","\n","Epoch 00265: val_loss improved from 0.00132 to 0.00129, saving model to Melhores_redes/atual.hdf5\n","Epoch 266/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0014\n","\n","Epoch 00266: val_loss did not improve from 0.00129\n","Epoch 267/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0013\n","\n","Epoch 00267: val_loss improved from 0.00129 to 0.00128, saving model to Melhores_redes/atual.hdf5\n","Epoch 268/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0013\n","\n","Epoch 00268: val_loss did not improve from 0.00128\n","Epoch 269/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0040 - val_loss: 0.0013\n","\n","Epoch 00269: val_loss did not improve from 0.00128\n","Epoch 270/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0013\n","\n","Epoch 00270: val_loss did not improve from 0.00128\n","Epoch 271/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0013\n","\n","Epoch 00271: val_loss improved from 0.00128 to 0.00126, saving model to Melhores_redes/atual.hdf5\n","Epoch 272/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0013\n","\n","Epoch 00272: val_loss did not improve from 0.00126\n","Epoch 273/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0040 - val_loss: 0.0013\n","\n","Epoch 00273: val_loss improved from 0.00126 to 0.00125, saving model to Melhores_redes/atual.hdf5\n","Epoch 274/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0012\n","\n","Epoch 00274: val_loss improved from 0.00125 to 0.00124, saving model to Melhores_redes/atual.hdf5\n","Epoch 275/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0013\n","\n","Epoch 00275: val_loss did not improve from 0.00124\n","Epoch 276/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0013\n","\n","Epoch 00276: val_loss did not improve from 0.00124\n","Epoch 277/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0013\n","\n","Epoch 00277: val_loss did not improve from 0.00124\n","Epoch 278/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0013\n","\n","Epoch 00278: val_loss did not improve from 0.00124\n","Epoch 279/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0013\n","\n","Epoch 00279: val_loss did not improve from 0.00124\n","Epoch 280/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0013\n","\n","Epoch 00280: val_loss did not improve from 0.00124\n","Epoch 281/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0013\n","\n","Epoch 00281: val_loss did not improve from 0.00124\n","Epoch 282/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0012\n","\n","Epoch 00282: val_loss improved from 0.00124 to 0.00122, saving model to Melhores_redes/atual.hdf5\n","Epoch 283/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0012\n","\n","Epoch 00283: val_loss did not improve from 0.00122\n","Epoch 284/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0012\n","\n","Epoch 00284: val_loss did not improve from 0.00122\n","Epoch 285/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0012\n","\n","Epoch 00285: val_loss did not improve from 0.00122\n","Epoch 286/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0012\n","\n","Epoch 00286: val_loss improved from 0.00122 to 0.00121, saving model to Melhores_redes/atual.hdf5\n","Epoch 287/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0012\n","\n","Epoch 00287: val_loss did not improve from 0.00121\n","Epoch 288/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0012\n","\n","Epoch 00288: val_loss improved from 0.00121 to 0.00121, saving model to Melhores_redes/atual.hdf5\n","Epoch 289/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0012\n","\n","Epoch 00289: val_loss improved from 0.00121 to 0.00119, saving model to Melhores_redes/atual.hdf5\n","Epoch 290/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0013\n","\n","Epoch 00290: val_loss did not improve from 0.00119\n","Epoch 291/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0040 - val_loss: 0.0012\n","\n","Epoch 00291: val_loss did not improve from 0.00119\n","Epoch 292/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0012\n","\n","Epoch 00292: val_loss did not improve from 0.00119\n","Epoch 293/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0012\n","\n","Epoch 00293: val_loss did not improve from 0.00119\n","Epoch 294/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0012\n","\n","Epoch 00294: val_loss did not improve from 0.00119\n","Epoch 295/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0012\n","\n","Epoch 00295: val_loss did not improve from 0.00119\n","Epoch 296/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0012\n","\n","Epoch 00296: val_loss improved from 0.00119 to 0.00119, saving model to Melhores_redes/atual.hdf5\n","Epoch 297/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0040 - val_loss: 0.0012\n","\n","Epoch 00297: val_loss did not improve from 0.00119\n","Epoch 298/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0012\n","\n","Epoch 00298: val_loss improved from 0.00119 to 0.00117, saving model to Melhores_redes/atual.hdf5\n","Epoch 299/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0012\n","\n","Epoch 00299: val_loss did not improve from 0.00117\n","Epoch 300/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0012\n","\n","Epoch 00300: val_loss improved from 0.00117 to 0.00116, saving model to Melhores_redes/atual.hdf5\n","Epoch 301/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0012\n","\n","Epoch 00301: val_loss did not improve from 0.00116\n","Epoch 302/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0012\n","\n","Epoch 00302: val_loss improved from 0.00116 to 0.00116, saving model to Melhores_redes/atual.hdf5\n","Epoch 303/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0012\n","\n","Epoch 00303: val_loss did not improve from 0.00116\n","Epoch 304/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0012\n","\n","Epoch 00304: val_loss did not improve from 0.00116\n","Epoch 305/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0012\n","\n","Epoch 00305: val_loss did not improve from 0.00116\n","Epoch 306/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0012\n","\n","Epoch 00306: val_loss did not improve from 0.00116\n","Epoch 307/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0012\n","\n","Epoch 00307: val_loss did not improve from 0.00116\n","Epoch 308/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0011\n","\n","Epoch 00308: val_loss improved from 0.00116 to 0.00112, saving model to Melhores_redes/atual.hdf5\n","Epoch 309/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0011\n","\n","Epoch 00309: val_loss improved from 0.00112 to 0.00112, saving model to Melhores_redes/atual.hdf5\n","Epoch 310/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0012\n","\n","Epoch 00310: val_loss did not improve from 0.00112\n","Epoch 311/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0012\n","\n","Epoch 00311: val_loss did not improve from 0.00112\n","Epoch 312/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0012\n","\n","Epoch 00312: val_loss did not improve from 0.00112\n","Epoch 313/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0012\n","\n","Epoch 00313: val_loss did not improve from 0.00112\n","Epoch 314/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00314: val_loss did not improve from 0.00112\n","Epoch 315/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0011\n","\n","Epoch 00315: val_loss did not improve from 0.00112\n","Epoch 316/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0040 - val_loss: 0.0011\n","\n","Epoch 00316: val_loss did not improve from 0.00112\n","Epoch 317/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0011\n","\n","Epoch 00317: val_loss did not improve from 0.00112\n","Epoch 318/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00318: val_loss did not improve from 0.00112\n","Epoch 319/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0012\n","\n","Epoch 00319: val_loss did not improve from 0.00112\n","Epoch 320/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0011\n","\n","Epoch 00320: val_loss did not improve from 0.00112\n","Epoch 321/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00321: val_loss improved from 0.00112 to 0.00111, saving model to Melhores_redes/atual.hdf5\n","Epoch 322/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0042 - val_loss: 0.0011\n","\n","Epoch 00322: val_loss improved from 0.00111 to 0.00111, saving model to Melhores_redes/atual.hdf5\n","Epoch 323/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00323: val_loss did not improve from 0.00111\n","Epoch 324/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0012\n","\n","Epoch 00324: val_loss did not improve from 0.00111\n","Epoch 325/2000\n","765/765 [==============================] - 2s 3ms/step - loss: 0.0040 - val_loss: 0.0011\n","\n","Epoch 00325: val_loss improved from 0.00111 to 0.00109, saving model to Melhores_redes/atual.hdf5\n","Epoch 326/2000\n","765/765 [==============================] - 2s 2ms/step - loss: 0.0041 - val_loss: 0.0011\n","\n","Epoch 00326: val_loss did not improve from 0.00109\n","Epoch 327/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0012\n","\n","Epoch 00327: val_loss did not improve from 0.00109\n","Epoch 328/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0011\n","\n","Epoch 00328: val_loss did not improve from 0.00109\n","Epoch 329/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0011\n","\n","Epoch 00329: val_loss improved from 0.00109 to 0.00108, saving model to Melhores_redes/atual.hdf5\n","Epoch 330/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0012\n","\n","Epoch 00330: val_loss did not improve from 0.00108\n","Epoch 331/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0011\n","\n","Epoch 00331: val_loss did not improve from 0.00108\n","Epoch 332/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00332: val_loss did not improve from 0.00108\n","Epoch 333/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0011\n","\n","Epoch 00333: val_loss did not improve from 0.00108\n","Epoch 334/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0011\n","\n","Epoch 00334: val_loss did not improve from 0.00108\n","Epoch 335/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00335: val_loss improved from 0.00108 to 0.00108, saving model to Melhores_redes/atual.hdf5\n","Epoch 336/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0040 - val_loss: 0.0011\n","\n","Epoch 00336: val_loss did not improve from 0.00108\n","Epoch 337/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00337: val_loss improved from 0.00108 to 0.00107, saving model to Melhores_redes/atual.hdf5\n","Epoch 338/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0010\n","\n","Epoch 00338: val_loss improved from 0.00107 to 0.00105, saving model to Melhores_redes/atual.hdf5\n","Epoch 339/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0011\n","\n","Epoch 00339: val_loss did not improve from 0.00105\n","Epoch 340/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0011\n","\n","Epoch 00340: val_loss did not improve from 0.00105\n","Epoch 341/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00341: val_loss did not improve from 0.00105\n","Epoch 342/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0040 - val_loss: 0.0010\n","\n","Epoch 00342: val_loss improved from 0.00105 to 0.00104, saving model to Melhores_redes/atual.hdf5\n","Epoch 343/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0011\n","\n","Epoch 00343: val_loss did not improve from 0.00104\n","Epoch 344/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0010\n","\n","Epoch 00344: val_loss did not improve from 0.00104\n","Epoch 345/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0011\n","\n","Epoch 00345: val_loss did not improve from 0.00104\n","Epoch 346/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0010\n","\n","Epoch 00346: val_loss improved from 0.00104 to 0.00103, saving model to Melhores_redes/atual.hdf5\n","Epoch 347/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0010\n","\n","Epoch 00347: val_loss did not improve from 0.00103\n","Epoch 348/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00348: val_loss did not improve from 0.00103\n","Epoch 349/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00349: val_loss did not improve from 0.00103\n","Epoch 350/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0031 - val_loss: 0.0011\n","\n","Epoch 00350: val_loss did not improve from 0.00103\n","Epoch 351/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00351: val_loss did not improve from 0.00103\n","Epoch 352/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0030 - val_loss: 0.0011\n","\n","Epoch 00352: val_loss did not improve from 0.00103\n","Epoch 353/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0011\n","\n","Epoch 00353: val_loss did not improve from 0.00103\n","Epoch 354/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00354: val_loss did not improve from 0.00103\n","Epoch 355/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0031 - val_loss: 0.0010\n","\n","Epoch 00355: val_loss improved from 0.00103 to 0.00102, saving model to Melhores_redes/atual.hdf5\n","Epoch 356/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00356: val_loss did not improve from 0.00102\n","Epoch 357/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0041 - val_loss: 0.0010\n","\n","Epoch 00357: val_loss did not improve from 0.00102\n","Epoch 358/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0012\n","\n","Epoch 00358: val_loss did not improve from 0.00102\n","Epoch 359/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00359: val_loss did not improve from 0.00102\n","Epoch 360/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0011\n","\n","Epoch 00360: val_loss did not improve from 0.00102\n","Epoch 361/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0010\n","\n","Epoch 00361: val_loss did not improve from 0.00102\n","Epoch 362/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0011\n","\n","Epoch 00362: val_loss did not improve from 0.00102\n","Epoch 363/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0010\n","\n","Epoch 00363: val_loss did not improve from 0.00102\n","Epoch 364/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00364: val_loss did not improve from 0.00102\n","Epoch 365/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0011\n","\n","Epoch 00365: val_loss did not improve from 0.00102\n","Epoch 366/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00366: val_loss did not improve from 0.00102\n","Epoch 367/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0010\n","\n","Epoch 00367: val_loss improved from 0.00102 to 0.00102, saving model to Melhores_redes/atual.hdf5\n","Epoch 368/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 9.9932e-04\n","\n","Epoch 00368: val_loss improved from 0.00102 to 0.00100, saving model to Melhores_redes/atual.hdf5\n","Epoch 369/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0011\n","\n","Epoch 00369: val_loss did not improve from 0.00100\n","Epoch 370/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0011\n","\n","Epoch 00370: val_loss did not improve from 0.00100\n","Epoch 371/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0010\n","\n","Epoch 00371: val_loss did not improve from 0.00100\n","Epoch 372/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0010\n","\n","Epoch 00372: val_loss did not improve from 0.00100\n","Epoch 373/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00373: val_loss did not improve from 0.00100\n","Epoch 374/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00374: val_loss did not improve from 0.00100\n","Epoch 375/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0010\n","\n","Epoch 00375: val_loss did not improve from 0.00100\n","Epoch 376/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00376: val_loss did not improve from 0.00100\n","Epoch 377/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0010\n","\n","Epoch 00377: val_loss did not improve from 0.00100\n","Epoch 378/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0010\n","\n","Epoch 00378: val_loss did not improve from 0.00100\n","Epoch 379/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 9.9635e-04\n","\n","Epoch 00379: val_loss improved from 0.00100 to 0.00100, saving model to Melhores_redes/atual.hdf5\n","Epoch 380/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0011\n","\n","Epoch 00380: val_loss did not improve from 0.00100\n","Epoch 381/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0011\n","\n","Epoch 00381: val_loss did not improve from 0.00100\n","Epoch 382/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0010\n","\n","Epoch 00382: val_loss did not improve from 0.00100\n","Epoch 383/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0011\n","\n","Epoch 00383: val_loss did not improve from 0.00100\n","Epoch 384/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0010\n","\n","Epoch 00384: val_loss did not improve from 0.00100\n","Epoch 385/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0030 - val_loss: 0.0011\n","\n","Epoch 00385: val_loss did not improve from 0.00100\n","Epoch 386/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0010\n","\n","Epoch 00386: val_loss did not improve from 0.00100\n","Epoch 387/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0031 - val_loss: 0.0010\n","\n","Epoch 00387: val_loss did not improve from 0.00100\n","Epoch 388/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0010\n","\n","Epoch 00388: val_loss did not improve from 0.00100\n","Epoch 389/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0011\n","\n","Epoch 00389: val_loss did not improve from 0.00100\n","Epoch 390/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0011\n","\n","Epoch 00390: val_loss did not improve from 0.00100\n","Epoch 391/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0010\n","\n","Epoch 00391: val_loss did not improve from 0.00100\n","Epoch 392/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0010\n","\n","Epoch 00392: val_loss did not improve from 0.00100\n","Epoch 393/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0035 - val_loss: 0.0010\n","\n","Epoch 00393: val_loss did not improve from 0.00100\n","Epoch 394/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0011\n","\n","Epoch 00394: val_loss did not improve from 0.00100\n","Epoch 395/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 9.8994e-04\n","\n","Epoch 00395: val_loss improved from 0.00100 to 0.00099, saving model to Melhores_redes/atual.hdf5\n","Epoch 396/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0011\n","\n","Epoch 00396: val_loss did not improve from 0.00099\n","Epoch 397/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0010\n","\n","Epoch 00397: val_loss did not improve from 0.00099\n","Epoch 398/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0011\n","\n","Epoch 00398: val_loss did not improve from 0.00099\n","Epoch 399/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0011\n","\n","Epoch 00399: val_loss did not improve from 0.00099\n","Epoch 400/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0011\n","\n","Epoch 00400: val_loss did not improve from 0.00099\n","Epoch 401/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 9.9699e-04\n","\n","Epoch 00401: val_loss did not improve from 0.00099\n","Epoch 402/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0031 - val_loss: 0.0011\n","\n","Epoch 00402: val_loss did not improve from 0.00099\n","Epoch 403/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0031 - val_loss: 0.0011\n","\n","Epoch 00403: val_loss did not improve from 0.00099\n","Epoch 404/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0011\n","\n","Epoch 00404: val_loss did not improve from 0.00099\n","Epoch 405/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0012\n","\n","Epoch 00405: val_loss did not improve from 0.00099\n","Epoch 406/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0028 - val_loss: 9.8933e-04\n","\n","Epoch 00406: val_loss improved from 0.00099 to 0.00099, saving model to Melhores_redes/atual.hdf5\n","Epoch 407/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0010\n","\n","Epoch 00407: val_loss did not improve from 0.00099\n","Epoch 408/2000\n","765/765 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0011\n","\n","Epoch 00408: val_loss did not improve from 0.00099\n","Epoch 409/2000\n","450/765 [================>.............] - ETA: 0s - loss: 0.0030"],"name":"stdout"}]}]}